{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from torchmetrics import AUROC  # additional dependency\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from oodtk import ODIN\n",
    "from oodtk.dataset.img import Textures, CIFAR10C, CIFAR10P, LSUNCrop, LSUNResize, TinyImageNetResize, TinyImageNetCrop\n",
    "from oodtk.model import WideResNet\n",
    "from oodtk.utils import is_unknown, OODMetrics\n",
    "from oodtk.transforms import ToRGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "trans = tvt.Compose([ToRGB(), tvt.Resize((32,32)), tvt.ToTensor(), tvt.Normalize(mean, std)])\n",
    "\n",
    "# setup data\n",
    "dataset_train = CIFAR10(root=\"data\", train=True, download=True, transform=trans)\n",
    "dataset_in_test = CIFAR10(root=\"data\", train=False, transform=trans)\n",
    "dataset_out_test1 = Textures(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test2 = LSUNCrop(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test3 = LSUNResize(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test4 = TinyImageNetResize(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test5 = TinyImageNetCrop(root=\"data\", download=True, transform=trans)\n",
    "dataset_test = dataset_in_test + dataset_out_test1 + dataset_out_test2 + dataset_out_test3 + dataset_out_test4 + dataset_out_test5\n",
    "# train_loader = DataLoader(dataset_train, batch_size=128, num_workers=20)\n",
    "test_loader = DataLoader(dataset_test, batch_size=64, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%% # setup model\n"
    }
   },
   "outputs": [],
   "source": [
    "model = WideResNet.from_pretrained(\"cifar10-pt\", num_classes=10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "odin = ODIN(model, eps=0.002, norm_std=std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c5fc4e31fc4b29acd943c609ffabbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/870 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     13\u001b[0m     metrics\u001b[38;5;241m.\u001b[39mupdate(odin\u001b[38;5;241m.\u001b[39mpredict(x), is_unknown(y))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(eps, \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     16\u001b[0m metrics\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/projects/oodtk/oodtk/utils.py:281\u001b[0m, in \u001b[0;36mOODMetrics.compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_at_tpr(s, l)\n\u001b[1;32m    274\u001b[0m fpr \u001b[38;5;241m=\u001b[39m fpr_at_tpr(s, l)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC\u001b[39m\u001b[38;5;124m\"\u001b[39m: auroc\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUPR-IN\u001b[39m\u001b[38;5;124m\"\u001b[39m: aupr_in\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUPR-OUT\u001b[39m\u001b[38;5;124m\"\u001b[39m: aupr_out\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACC95TPR\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFPR95TPR\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mfpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n\u001b[1;32m    282\u001b[0m }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "metrics = OODMetrics()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for eps in [0.0, 0.0004, 0.0008, 0.0014, 0.002, 0.0024, 0.0028, 0.0032, 0.0038, 0.0048]:\n",
    "        odin.eps = eps\n",
    "        for batch in tqdm(test_loader):\n",
    "            x, y = batch\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            metrics.update(odin.predict(x), is_unknown(y))\n",
    "\n",
    "        print(eps, metrics.compute())\n",
    "        metrics.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_in_test = CIFAR10(root=\"data\", train=False, transform=trans)\n",
    "# dataset_out_test = CIFAR10C(root=\"data\", subset=\"all\", download=True, transform=trans)\n",
    "# dataset_test = dataset_in_test +  dataset_out_test\n",
    "# test_loader = DataLoader(dataset_test, batch_size=128)\n",
    "#\n",
    "# auroc = AUROC(num_classes=2)\n",
    "# model.eval()\n",
    "#\n",
    "#\n",
    "# for batch in tqdm(test_loader):\n",
    "#     x, y = batch\n",
    "#     x = x.cuda()\n",
    "#     y = y.cuda()\n",
    "#\n",
    "#     auroc.update(odin(x), is_unknown(y))\n",
    "#\n",
    "# print(eps, auroc.compute())\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_in_test = CIFAR10(root=\"data\", train=False, transform=trans)\n",
    "# dataset_out_test = CIFAR10P(root=\"data\", download=True, transform=trans)\n",
    "# dataset_test = dataset_in_test +  dataset_out_test\n",
    "# test_loader = DataLoader(dataset_test, batch_size=128)\n",
    "#\n",
    "# model.eval()\n",
    "#\n",
    "# for batch in tqdm(test_loader):\n",
    "#     x, y = batch\n",
    "#     x = x.cuda()\n",
    "#     y = y.cuda()\n",
    "#\n",
    "# auroc.update(odin(x), is_unknown(y))\n",
    "#\n",
    "# print(auroc.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_out_test = CIFAR10C(root=\"data\", subset=\"all\", download=True, transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
