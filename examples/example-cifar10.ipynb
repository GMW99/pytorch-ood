{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from torchmetrics import AUROC  # additional dependency\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from oodtk import NegativeEnergy, Softmax, ODIN\n",
    "from oodtk.dataset.img import Textures, CIFAR10C, CIFAR10P, LSUNCrop, LSUNResize, TinyImageNetResize, TinyImageNetCrop\n",
    "from oodtk.model import WideResNet\n",
    "from oodtk.utils import is_unknown, OODMetrics\n",
    "from oodtk.transforms import ToRGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "trans = tvt.Compose([ToRGB(), tvt.Resize((32,32)), tvt.ToTensor(), tvt.Normalize(mean, std)])\n",
    "\n",
    "# setup data\n",
    "dataset_train = CIFAR10(root=\"data\", train=True, download=True, transform=trans)\n",
    "dataset_in_test = CIFAR10(root=\"data\", train=False, transform=trans)\n",
    "dataset_out_test1 = Textures(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test2 = LSUNCrop(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test3 = LSUNResize(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test4 = TinyImageNetResize(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test5 = TinyImageNetCrop(root=\"data\", download=True, transform=trans)\n",
    "dataset_test = dataset_in_test + dataset_out_test1 + dataset_out_test2 + dataset_out_test3 + dataset_out_test4 + dataset_out_test5\n",
    "train_loader = DataLoader(dataset_train, batch_size=128, num_workers=20)\n",
    "test_loader = DataLoader(dataset_test, batch_size=128, num_workers=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% # setup model\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ki/.local/share/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 0.9857486486434937, 'AUPR-IN': 0.9964964389801025, 'AUPR-OUT': 0.9549047946929932, 'ACC95TPR': 0.9451833367347717, 'FPR95TPR': 0.07680000364780426}\n"
     ]
    }
   ],
   "source": [
    "model = WideResNet.from_pretrained(\"oe-cifar10-tune\", num_classes=10).eval().cuda()\n",
    "method = Softmax(model).cuda()\n",
    "metrics = OODMetrics()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for n, batch in enumerate(test_loader):\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        metrics.update(method.predict(x), y)\n",
    "\n",
    "print(metrics.compute())\n",
    "metrics.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/435 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77ed7488e13d4809aa3d922d399b928b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 0.9888905882835388, 'AUPR-IN': 0.996794581413269, 'AUPR-OUT': 0.965325653553009, 'ACC95TPR': 0.9515097141265869, 'FPR95TPR': 0.041600000113248825}\n"
     ]
    }
   ],
   "source": [
    "model = WideResNet.from_pretrained(\"er-cifar10-tune\", num_classes=10).eval().cuda()\n",
    "energy = NegativeEnergy(model)\n",
    "metrics = OODMetrics()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        metrics.update(energy.predict(x), y)\n",
    "\n",
    "print(metrics.compute())\n",
    "metrics.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/435 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23c13b04293f4fe5b75b80d1c25acec8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 0.9217170476913452, 'AUPR-IN': 0.9772027730941772, 'AUPR-OUT': 0.79755699634552, 'ACC95TPR': 0.9085010886192322, 'FPR95TPR': 0.2809000015258789}\n"
     ]
    }
   ],
   "source": [
    "model = WideResNet.from_pretrained(\"cifar10-pt\", num_classes=10).eval().cuda()\n",
    "method = Softmax(model)\n",
    "metrics = OODMetrics()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        metrics.update(method.predict(x), y)\n",
    "\n",
    "print(metrics.compute())\n",
    "metrics.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/435 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f49f95126da64f298999823ef9068ea3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 0.9384509325027466, 'AUPR-IN': 0.9850852489471436, 'AUPR-OUT': 0.767615795135498, 'ACC95TPR': 0.9011861681938171, 'FPR95TPR': 0.3215999901294708}\n"
     ]
    }
   ],
   "source": [
    "model = WideResNet.from_pretrained(\"cifar10-pt\", num_classes=10).eval().cuda()\n",
    "method = NegativeEnergy(model)\n",
    "metrics = OODMetrics()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        metrics.update(method.predict(x), y)\n",
    "\n",
    "print(metrics.compute())\n",
    "metrics.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ki/.local/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/435 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77c2745ba9234bd1ac060a38585c8a02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 0.4104202389717102, 'AUPR-IN': 0.7914378643035889, 'AUPR-OUT': 0.14317642152309418, 'ACC95TPR': 0.7848490476608276, 'FPR95TPR': 0.9783999919891357}\n"
     ]
    }
   ],
   "source": [
    "model = WideResNet.from_pretrained(\"cifar10-pt\", num_classes=10).eval().cuda()\n",
    "odin = ODIN(model, eps=0.002, norm_std=std)\n",
    "metrics = OODMetrics()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "\n",
    "        metrics.update(method.predict(x).detach(), y)\n",
    "\n",
    "print(metrics.compute())\n",
    "metrics.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
