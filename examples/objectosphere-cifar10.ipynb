{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from torch.optim import Adam\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm.notebook import tqdm\n",
    "from torchmetrics import Accuracy, AUROC\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from pytorch_ood.utils import is_known, is_unknown, contains_known, contains_unknown\n",
    "from pytorch_ood.loss import ObjectosphereLoss\n",
    "from pytorch_ood.dataset.img import Textures, CIFAR10C, LSUNCrop, LSUNResize, TinyImageNetResize, TinyImageNetCrop\n",
    "from pytorch_ood.dataset.img import TinyImages300k\n",
    "from pytorch_ood.model import WideResNet\n",
    "from pytorch_ood.transforms import ToRGB, ToUnknown\n",
    "from pytorch_ood.metrics import OODMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "trans = tvt.Compose([ToRGB(), tvt.Resize((32,32)), tvt.ToTensor(), tvt.Normalize(mean, std)])\n",
    "\n",
    "# setup data\n",
    "dataset_in_train = CIFAR10(root=\"data\", train=True, download=True, transform=trans)\n",
    "# dataset_in_test = CIFAR10(root=\"data\", train=False, transform=trans)\n",
    "dataset_out_train = Subset(\n",
    "    TinyImages300k(root=\"/home/ki/datasets/\", transform=trans, target_transform=ToUnknown(), download=True), indices=range(120000))\n",
    "\n",
    "train_loader = DataLoader(dataset_in_train + dataset_out_train, batch_size=128, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = WideResNet.from_pretrained(\"cifar10-pt\", num_classes=10)\n",
    "opti = Adam(params=model.parameters(), lr=0.001)\n",
    "crit = ObjectosphereLoss()\n",
    "scheduler = CosineAnnealingLR(opti, T_max=len(train_loader) * 10)\n",
    "model = model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv2/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8304b6851f9d417e9f487f87b5fd6307"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv2/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: `pos_label` automatically set 1.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2464a2218e94d10834fe063a25e1917"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dbb34dffbd54a8c9effbdce8cf474db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebff2b34a0d1409d82dd22e6d8d8cc14"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c7e274cb8dc49bea3c6bac147c11c3a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68750727f38f4b1f93d5cc3d3db6fad7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32fdd86fb7694ee193233ce8387ae209"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8038e61ff3ce42c3b25a32fb0e5df329"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "340a49eafc644ebe92a2552adff4e082"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1329 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6a45300c60e4326b61edc4abfe12370"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "acc = Accuracy(num_classes=10).cuda()\n",
    "auroc = AUROC(num_classes=2).cuda()\n",
    "\n",
    "for epoch in range(10):\n",
    "    bar = tqdm(train_loader)\n",
    "    for batch in bar:\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        z = model(x)\n",
    "\n",
    "        loss = crit(z, y)\n",
    "        opti.zero_grad()\n",
    "        loss.backward()\n",
    "        opti.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        acc.update(z[is_known(y)],y[is_known(y)])\n",
    "        auroc.update(ObjectosphereLoss.score(z),is_unknown(y))\n",
    "        bar.set_postfix({\"loss\": loss.item(), \"acc\": acc.compute().item(), \"auroc\": auroc.compute().item()})\n",
    "\n",
    "    acc.reset()\n",
    "    auroc.reset()\n",
    "\n",
    "torch.save(model, \"/home/ki/cifar10-objectosphere.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv2/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ki/.local/share/anaconda3/envs/myenv2/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/435 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5ed63672f60422b902620da23c291bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8728, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ki/.local/share/anaconda3/envs/myenv2/lib/python3.8/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: `pos_label` automatically set 1.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/ki/.local/share/anaconda3/envs/myenv2/lib/python3.8/site-packages/torchmetrics/functional/classification/precision_recall_curve.py:156: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  thresholds = tensor(reversed(thresholds[sl]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AUROC': 0.9616478681564331, 'AUPR-IN': 0.9888243675231934, 'AUPR-OUT': 0.875281035900116, 'ACC95TPR': 0.9318296313285828, 'FPR95TPR': 0.15109999477863312}\n"
     ]
    }
   ],
   "source": [
    "dataset_in_test = CIFAR10(root=\"data\", train=False, transform=trans)\n",
    "dataset_out_test1 = Textures(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test2 = LSUNCrop(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test3 = LSUNResize(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test4 = TinyImageNetResize(root=\"data\", download=True, transform=trans)\n",
    "dataset_out_test5 = TinyImageNetCrop(root=\"data\", download=True, transform=trans)\n",
    "dataset_test = dataset_in_test + dataset_out_test1 + dataset_out_test2 + dataset_out_test3 + dataset_out_test4 + dataset_out_test5\n",
    "test_loader = DataLoader(dataset_test, batch_size=128)\n",
    "\n",
    "acc = Accuracy(num_classes=10).cuda()\n",
    "metrics = OODMetrics()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        z = model(x)\n",
    "        acc.update(z[is_known(y)],y[is_known(y)])\n",
    "        metrics.update(ObjectosphereLoss.score(z),y)\n",
    "\n",
    "print(acc.compute())\n",
    "print(metrics.compute())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce1bb837adbf40028a40aadeaf993e65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8500, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from pytorch_ood.dataset.img import Textures, CIFAR10C, LSUNCrop, LSUNResize, TinyImageNetResize, TinyImageNetCrop\n",
    "cifarc = CIFAR10C(root=\"data/\", subset=\"all\", download=True, transform=trans)\n",
    "test_loader = DataLoader(cifarc, batch_size=128)\n",
    "\n",
    "acc = Accuracy(num_classes=10).cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        x, y = batch\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        z = model(x)\n",
    "        acc.update(z[is_known(y)],y[is_known(y)])\n",
    "\n",
    "print(acc.compute())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv2",
   "language": "python",
   "display_name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
